{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8RZOuS9LWQvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb1fda78-1c41-4ecf-999f-99706708e633"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lMHwYXHXCar3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99621627-6a6f-4e70-87d5-87daf38fc117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-23 21:41:26--  https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 172.67.70.149, 104.26.3.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358233 (350K) [text/tab-separated-values]\n",
            "Saving to: ‘train-data.tsv’\n",
            "\n",
            "\rtrain-data.tsv        0%[                    ]       0  --.-KB/s               \rtrain-data.tsv      100%[===================>] 349.84K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-05-23 21:41:27 (10.1 MB/s) - ‘train-data.tsv’ saved [358233/358233]\n",
            "\n",
            "--2024-05-23 21:41:27--  https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 172.67.70.149, 104.26.3.33, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118774 (116K) [text/tab-separated-values]\n",
            "Saving to: ‘valid-data.tsv’\n",
            "\n",
            "valid-data.tsv      100%[===================>] 115.99K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-05-23 21:41:27 (5.18 MB/s) - ‘valid-data.tsv’ saved [118774/118774]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/train-data.tsv\n",
        "!wget https://cdn.freecodecamp.org/project-data/sms/valid-data.tsv\n",
        "\n",
        "train_file_path = \"train-data.tsv\"\n",
        "test_file_path = \"valid-data.tsv\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading data"
      ],
      "metadata": {
        "id": "0vXYhCUxZc0b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "g_h508FEClxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b824f274-1290-455f-85ab-b037fb0feeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text\n",
            "0   ham  ahhhh...just woken up!had a bad dream about u ...\n",
            "1   ham                           you can never do nothing\n",
            "2   ham  now u sound like manky scouse boy steve,like! ...\n",
            "3   ham  mum say we wan to go then go... then she can s...\n",
            "4   ham  never y lei... i v lazy... got wat? dat day ü ...\n",
            "   label                                               text\n",
            "0      0  ahhhh...just woken up!had a bad dream about u ...\n",
            "1      0                           you can never do nothing\n",
            "2      0  now u sound like manky scouse boy steve,like! ...\n",
            "3      0  mum say we wan to go then go... then she can s...\n",
            "4      0  never y lei... i v lazy... got wat? dat day ü ...\n"
          ]
        }
      ],
      "source": [
        "# Reading the dataset\n",
        "df_train = pd.read_csv(\"train-data.tsv\", sep = '\\t', header=None, names = ['label', 'text'])\n",
        "df_valid = pd.read_csv(\"valid-data.tsv\", sep = '\\t', header=None, names = ['label', 'text'])\n",
        "\n",
        "print(df_train.head())\n",
        "\n",
        "# Transforming 'ham' to 0 and 'spam' to 1\n",
        "df_train['label'] = pd.Categorical(df_train['label']).codes\n",
        "df_valid['label'] = pd.Categorical(df_valid['label']).codes\n",
        "\n",
        "print(df_train.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre processing the data"
      ],
      "metadata": {
        "id": "KRVznc0FZfiK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zOMKywn4zReN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b41bf62-36a4-40f4-b801-8de26bccd344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove non-alphanumeric tokens and stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
        "\n",
        "    # Lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    cleaned_text = ' '.join(tokens)\n",
        "    return cleaned_text\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(clean_text)\n",
        "df_valid['text'] = df_valid['text'].apply(clean_text)\n",
        "\n",
        "print(df_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYO6wfe7Zigb",
        "outputId": "5eb8631b-ab8e-4f08-b40f-2dabbd159335"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text\n",
            "0      0  ahhhh woken bad dream u tho dont like u right ...\n",
            "1      0                                      never nothing\n",
            "2      0  u sound like manky scouse boy steve like trave...\n",
            "3      0  mum say wan go go shun bian watch da glass exh...\n",
            "4      0  never lei v lazy got wat dat day ü send da url...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize only using training data\n",
        "max_words = 1000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df_train['text'])\n",
        "\n",
        "# Transform the text to sequences\n",
        "sequences_train = tokenizer.texts_to_sequences(df_train['text'])\n",
        "sequences_val = tokenizer.texts_to_sequences(df_valid['text'])\n",
        "\n",
        "# Find the maximum length of sequences in the training data for padding\n",
        "max_length = 500\n",
        "\n",
        "# Pad sequences to ensure they are of the same length\n",
        "X_train = pad_sequences(sequences_train, maxlen=max_length)\n",
        "X_val = pad_sequences(sequences_val, maxlen=max_length)\n",
        "\n",
        "# Convert labels to numpy arrays\n",
        "y_train = np.array(df_train['label'])\n",
        "y_val = np.array(df_valid['label'])"
      ],
      "metadata": {
        "id": "7a499bGsZj9T"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the model"
      ],
      "metadata": {
        "id": "zFfXvB2JZmWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "input_layer= x = Input(max_length)\n",
        "x = Embedding(max_words, 125)(x)\n",
        "x = LSTM(128, dropout = 0.5)(x)\n",
        "\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=x)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts1kigTVZlZW",
        "outputId": "075ddc77-ca4d-4977-cc43-393b9b20bcc1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 500)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 500, 125)          125000    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 128)               130048    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 263690 (1.01 MB)\n",
            "Trainable params: 263562 (1.01 MB)\n",
            "Non-trainable params: 128 (512.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD, AdamW, Adam\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min', restore_best_weights=True)\n",
        "model.compile(optimizer = Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "    x = X_train,\n",
        "    y = y_train,\n",
        "    epochs = 10,\n",
        "    batch_size = 128,\n",
        "    validation_data = (X_val, y_val),\n",
        "    shuffle = True,\n",
        "    callbacks = [early_stopping],\n",
        "    class_weight = {0: 1.5, 1: 1.0}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFwZci6zZpeE",
        "outputId": "15f00c9a-f24d-42e2-feaa-8ab2932f9e86"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "33/33 [==============================] - 6s 119ms/step - loss: 0.5580 - accuracy: 0.8497 - val_loss: 0.4135 - val_accuracy: 0.9353\n",
            "Epoch 2/10\n",
            "33/33 [==============================] - 4s 119ms/step - loss: 0.0970 - accuracy: 0.9801 - val_loss: 0.2662 - val_accuracy: 0.9756\n",
            "Epoch 3/10\n",
            "33/33 [==============================] - 2s 70ms/step - loss: 0.0605 - accuracy: 0.9871 - val_loss: 0.1938 - val_accuracy: 0.9777\n",
            "Epoch 4/10\n",
            "33/33 [==============================] - 3s 83ms/step - loss: 0.0437 - accuracy: 0.9907 - val_loss: 0.1756 - val_accuracy: 0.9777\n",
            "Epoch 5/10\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0374 - accuracy: 0.9902 - val_loss: 0.1389 - val_accuracy: 0.9806\n",
            "Epoch 6/10\n",
            "33/33 [==============================] - 2s 60ms/step - loss: 0.0259 - accuracy: 0.9950 - val_loss: 0.1063 - val_accuracy: 0.9820\n",
            "Epoch 7/10\n",
            "33/33 [==============================] - 2s 74ms/step - loss: 0.0248 - accuracy: 0.9935 - val_loss: 0.1006 - val_accuracy: 0.9842\n",
            "Epoch 8/10\n",
            "33/33 [==============================] - 2s 54ms/step - loss: 0.0228 - accuracy: 0.9950 - val_loss: 0.0820 - val_accuracy: 0.9835\n",
            "Epoch 9/10\n",
            "33/33 [==============================] - 2s 49ms/step - loss: 0.0271 - accuracy: 0.9928 - val_loss: 0.0768 - val_accuracy: 0.9835\n",
            "Epoch 10/10\n",
            "33/33 [==============================] - 2s 55ms/step - loss: 0.0227 - accuracy: 0.9955 - val_loss: 0.0670 - val_accuracy: 0.9820\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7eb2a1cba260>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "3dLcXyW0ZrsP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "J9tD9yACG6M9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae291a2-4940-412c-949a-513bfb40ef72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "[0.97976935, 'ham']\n"
          ]
        }
      ],
      "source": [
        "# function to predict messages based on model\n",
        "# (should return list containing prediction and label, ex. [0.008318834938108921, 'ham'])\n",
        "\n",
        "ham_spam = {0: \"ham\", 1: \"spam\"}\n",
        "\n",
        "def predict_message(pred_text):\n",
        "    cleaned_text = clean_text(pred_text)\n",
        "    sequence = tokenizer.texts_to_sequences([cleaned_text])\n",
        "    x = pad_sequences(sequence, maxlen=max_length)\n",
        "\n",
        "    prediction = model.predict(x)\n",
        "\n",
        "    # Selecting from which class the result belong according to the index with the higher probability\n",
        "    result = np.argmax(prediction[0])\n",
        "\n",
        "    confidence = prediction[0][result]\n",
        "\n",
        "    return ([confidence, ham_spam[result]])\n",
        "\n",
        "pred_text = \"how are you doing today?\"\n",
        "\n",
        "prediction = predict_message(pred_text)\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Dxotov85SjsC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "818ede60-3462-4eac-c7b0-a5619c74070f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "You passed the challenge. Great job!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to test your function and model. Do not modify contents.\n",
        "def test_predictions():\n",
        "  test_messages = [\"how are you doing today\",\n",
        "                   \"sale today! to stop texts call 98912460324\",\n",
        "                   \"i dont want to go. can we try it a different day? available sat\",\n",
        "                   \"our new mobile video service is live. just install on your phone to start watching.\",\n",
        "                   \"you have won £1000 cash! call to claim your prize.\",\n",
        "                   \"i'll bring it tomorrow. don't forget the milk.\",\n",
        "                   \"wow, is your arm alright. that happened to me one time too\"\n",
        "                  ]\n",
        "\n",
        "  test_answers = [\"ham\", \"spam\", \"ham\", \"spam\", \"spam\", \"ham\", \"ham\"]\n",
        "  passed = True\n",
        "\n",
        "  for msg, ans in zip(test_messages, test_answers):\n",
        "    prediction = predict_message(msg)\n",
        "    if prediction[1] != ans:\n",
        "\n",
        "        print(f\"pred: {prediction[1]} - answer: {ans}\\n\")\n",
        "\n",
        "        passed = False\n",
        "\n",
        "  if passed:\n",
        "    print(\"You passed the challenge. Great job!\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying.\")\n",
        "\n",
        "test_predictions()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {},
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}